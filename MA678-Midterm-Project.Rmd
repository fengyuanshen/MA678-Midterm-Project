---
title: "Data-Driven Analysis and Forecasting of the Los Angeles Airbnb Market"
subtitle : "MA678 Midterm Project"
author: "Fengyuan Shen (Vincent)"
date: "2023-12-09"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

## Introduction

Airbnb的背景。这篇project试图解决什么问题，用了什么方法，干了哪些事。文章的整体结构。

## Literature Review

In recent years, the rise and development of Airbnb has had a profound impact on urban housing markets and community dynamics. Studies have shown that the distribution of Airbnb listings is influenced by a number of factors. Deboosere et al.[1] uses hedonic regression models to analyze Airbnb transactions in New York City. This study finds that locational factors, particularly transit accessibility, greatly influence listing prices and revenues. It also indicates a trend towards the professionalization of the short-term rental market, leading to increased revenue for a smaller segment of hosts and potentially displacing long-term residents in accessible neighborhoods.

According to a comprehensive review by Guttentag [2][3] of 132 peer-reviewed journal articles, research on Airbnb has been categorized into six primary domains: the preferences and motivations of Airbnb guests, the incentives and objectives of hosts, the impact of Airbnb on local destinations, regulatory aspects, its influence on the tourism sector, and the operational dynamics of the company itself. The study highlights that Airbnb rentals tend to be located in areas with better transit services, proximity to city centers, and higher median house values and incomes, suggesting a risk of social inequality in the sharing economy.

In summary, these studies highlight a variety of factors that can affect Airbnb's listing prices. These insights have informed the modeling and analysis in my project, which focuses on identifying and analyzing the factors that can impact the pricing of Airbnb listings. This involves examining how elements like location, socioeconomic status, and broader market trends.

## Method

The initial dataset was segmented into ten distinct sections. To facilitate a comprehensive analysis, I consolidated these segments into a single dataset, subsequently named **`listings.csv`**.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(leaflet)
library(ggmap)
library(reshape2)
library(gridExtra)
library(lubridate)
library(stringr)
library(lme4)
library(rstanarm)
library(caTools)
library(caret)
library(knitr)
```

```{r echo=FALSE}
# listings <- read.csv("data/listings.csv", header = T)
# calendar <- read.csv("data/calendar.csv", header = T)
# reviews <- read.csv("data/reviews.csv", header = T)
```

```{r echo=FALSE}
# Combine data
# file_list <- list.files(path = "listings_data", pattern = "*.csv", full.names = TRUE)
# combined_data <- bind_rows(lapply(file_list, read.csv))
# write.csv(combined_data, "listings_data/listings.csv", row.names = FALSE)
```

```{r echo=FALSE}
# read csv
listings <- read.csv("data/listings.csv", header = T)
```

### Data Cleaning

In the data cleaning phase, the dataset comprised 75 variables, presenting a complexity that necessitated reduction for effective model fitting. Drawing upon insights gathered from the literature review, I meticulously chose over 30 variables deemed pertinent for predicting Airbnb's listing prices. The following table delineates a subset of these selected variables.

```{r echo=FALSE}
listings_data <- listings |> 
  select(id, host_id, host_name, host_since, host_response_time, host_response_rate,
         host_acceptance_rate, host_is_superhost, host_listings_count,
         host_identity_verified, latitude, longitude, property_type, room_type,
         accommodates, bathrooms_text, bedrooms, beds, price, minimum_nights,
         maximum_nights, number_of_reviews, review_scores_rating, review_scores_accuracy,
         review_scores_cleanliness, review_scores_checkin, review_scores_communication,
         review_scores_location, review_scores_value, instant_bookable, host_neighbourhood)
```

```{r echo=FALSE}
kable(head(listings_data[,c(3,4,16:19,23)]))
```

This is a summary of the dataset.

```{r echo=FALSE}
summary(listings_data)
```

Upon preliminary examination of the dataset, it becomes evident that the removal of missing values and outliers is imperative. Their presence could potentially skew the predictive accuracy of the model.

For the **`price`** column, I removed all non-numeric characters and calculated the first quartile (Q1) and third quartile (Q3) of the column, as well as the interquartile (IQR). They are then used to define a range of outliers. Finally, the dataset is filtered to retain only the price values in this range.

In the **`host_response_time`**, **`host_is_superhost`**, **`host_identity_verified`**, **`instant_bookable`**, **`bathrooms_text`**, and **`room_type`** columns, I converted categorical variables into numeric types, simultaneously filtering out rows containing NA values. This transformation not only streamlined the dataset but also enhanced its suitability for quantitative analysis and modeling.

Regarding the **`host_response_rate`** column, I transformed percentage strings into numeric values, thereby standardizing the data format for more effective subsequent analyses.

```{r echo=FALSE}
# Price
# Omit missing values
listings_data <- na.omit(listings_data)

# Converts the data format of the Price column
listings_data$price <- as.numeric(str_replace_all(listings_data$price, "[^0-9.]", ""))

# Remove outliers in the Price column
Q1 <- quantile(listings_data$price, 0.25)
Q3 <- quantile(listings_data$price, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
listings_data <- listings_data |> filter(price >= lower_bound & price <= upper_bound)
```

```{r echo=FALSE}
# Host response
# Converts categorical variables to numeric types
listings_data <- listings_data |> 
  mutate(host_response_time = case_when(
    host_response_time == "within an hour" ~ 0,
    host_response_time == "within a few hours" ~ 1,
    host_response_time  == "a few days or more" ~ 2,
    TRUE ~ NA  # If neither match, set the column to NA
  )) |> 
  filter(!is.na(host_response_time)) # Filter out rows with NA values
```

```{r echo=FALSE}
# Host is superhost
listings_data <- listings_data |> filter(host_is_superhost %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$host_is_superhost <- ifelse(listings_data$host_is_superhost == 'f', 0, 1)
```

```{r echo=FALSE}
# Host identify verified
listings_data <- listings_data |> filter(host_identity_verified %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$host_identity_verified <- ifelse(listings_data$host_identity_verified == 'f',
                                               0, 1)
```

```{r echo=FALSE}
# Instant bookable
listings_data <- listings_data |> filter(instant_bookable %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$instant_bookable <- ifelse(listings_data$instant_bookable == 'f', 0, 1)
```

```{r echo=FALSE, warning=FALSE}
# Converts a percentage string to a numeric type
listings_data$host_response_rate <- 
  as.numeric(sub("%", "", listings_data$host_response_rate)) / 100
listings_data$host_acceptance_rate <- 
  as.numeric(sub("%", "", listings_data$host_acceptance_rate)) / 100
listings_data <- drop_na(listings_data, host_response_rate, host_acceptance_rate)
```

```{r echo=FALSE}
# Bathrooms text
listings_data <- listings_data |> 
  mutate(bathrooms = case_when(
    bathrooms_text %in% c("Half-bath", "Shared half-bath") ~ 0.5,
    bathrooms_text %in% c("1 bath", "1 shared bath", "1 private bath") ~ 1,
    bathrooms_text %in% c("1.5 baths", "1.5 shared baths") ~ 1.5,
    bathrooms_text %in% c("2 baths", "2 shared baths") ~ 2,
    bathrooms_text %in% c("2.5 baths") ~ 2.5,
    bathrooms_text %in% c("3 baths", "3 shared baths") ~ 3,
    bathrooms_text %in% c("3.5 baths", "3.5 shared baths") ~ 3.5,
    bathrooms_text %in% c("4 baths") ~ 4,
    bathrooms_text %in% c("4.5 baths") ~ 4.5,
    bathrooms_text %in% c("5 baths") ~ 5,
    bathrooms_text %in% c("5.5 baths") ~ 5.5,
    bathrooms_text %in% c("6 baths") ~ 6,
    bathrooms_text %in% c("7 baths") ~ 7,
    bathrooms_text %in% c("7.5 baths") ~ 7.5,
    bathrooms_text %in% c("8 baths") ~ 8,
    bathrooms_text %in% c("11 baths", "11 shared baths", "11.5 shared baths") ~ 11,
    bathrooms_text %in% c("11.5 shared baths") ~ 11.5,
    TRUE ~ NA_real_  # For other values, set to NA
  )) |> 
  filter(!is.na(bathrooms)) |>   # Remove rows with NA in bathrooms
  # Keep bathrooms column after bathrooms_text
  relocate(bathrooms, .after = bathrooms_text) |>   
  select(-bathrooms_text)  # Remove the old bathrooms_text column
```

```{r echo=FALSE}
# Room type
listings_data <- listings_data |> 
  mutate(room = case_when(
    room_type %in% c("Entire home/apt") ~ 0,
    room_type %in% c("Private room") ~ 1,
    room_type %in% c("Hotel room") ~ 2,
    TRUE ~ NA_real_  # For other values, set to NA
  )) |> 
  filter(!is.na(room)) |>  # Remove rows with NA in room_type
  # Keep room column after bathrooms_text
  relocate(room, .after = room_type)
```

### EDA

Following the completion of the data cleaning process, the subsequent phase involves conducting exploratory data analysis (EDA). This critical step will facilitate a deeper and more nuanced understanding of the dataset.

Initially, to ascertain the linear relationships between various variables, I constructed a heatmap. This graphical representation elucidates the correlation coefficients among different variables, providing a visual overview of their interrelationships.

```{r fig.width=7,fig.height=6,echo=FALSE}
# Heatmap
# Select numerical columns for correlation analysis
numeric_data <- listings_data[, c('host_response_time', 'host_response_rate',
                                  'host_acceptance_rate', 'host_is_superhost',
                                  'host_listings_count', 'host_identity_verified',
                                  'latitude', 'longitude', 'room', 'accommodates',
                                  'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights',
                                  'maximum_nights', 'number_of_reviews', 
                                  'review_scores_rating', 'review_scores_accuracy',
                                  'review_scores_cleanliness', 'review_scores_checkin',
                                  'review_scores_communication', 'review_scores_location',
                                  'review_scores_value', 'instant_bookable')]

# Correlation matrix
correlation_matrix <- cor(numeric_data, use="complete.obs")

# Heatmap
melted_correlation <- melt(correlation_matrix)
ggplot(data = melted_correlation, aes(Var1, Var2, fill = value)) +
    geom_tile() +
    geom_text(aes(label = sprintf("%.2f", value)), size = 1.7, vjust = 0.5) +
    scale_fill_gradientn(colours = c("#03045E", "#023E8A", "#277DA1", "#577590", "#4D908E",
                                     "#43AA8B", "#90BE6D", "#F9C74F", "#F9844A", "#F8961E",
                                     "#F3722C", "#F94144", "#DC2F02", "#D00000"),
                         limits = c(-1, 1)) +
    theme_minimal() +
    labs(title = "Correlation Matrix of Variables", x = '', y = '') +
    theme(
      plot.title = element_text(hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
      )
```

The heatmap analysis reveals that the **`price`** variable exhibits significant correlations with several factors, including **`host_is_superhost`**, **`room_type`**, **`accommodates`**, **`bathrooms`**, **`bedrooms`**, **`beds`**, **`minimum_nights`**, **`number_of_reviews`**, **`review_scores_ratings`**, and **`review_scores_location`**.

However, it is crucial to note that the correlation matrix primarily reflects linear relationships between variables. In some instances, the associations might be non-linear, as exemplified by the relationship between **`price`** and geographical coordinates (**`latitude`** and **`longitude`**). Consistent with insights from existing literature, Airbnb's listing price is influenced by geographic location. Accordingly, incorporating **`latitude`** and **`longitude`** into the model building process is a critical step to capture these complex spatial dynamics.

Before delving into the exploration of other variables, an initial analysis was conducted to examine the distribution of Airbnb's listing prices.

```{r echo=FALSE}
# Price Distribution
ggplot(listings_data, aes(x = price)) +
  geom_histogram(binwidth = 10, fill = "#D62828", color = "black") +
  geom_density(aes(y = after_stat(count) * 10), color = "#003566", linewidth = 1) +
  labs(title = "Price Distribution", x = "Price", y = "Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Scatter plot of the relationship between location and price
register_stadiamaps(key = "5a10d16e-591e-4614-be7c-c5294374aac7")
los_angeles_map <- get_stadiamap(bbox = c(left = -118.55, bottom = 33.95, right = -118.15, 
                                          top = 34.25), zoom = 12, maptype = "outdoors")
```

```{r echo=FALSE,warning=FALSE}
ggmap(los_angeles_map) +
  geom_point(data = listings_data, aes(x = longitude, y = latitude, color = price), 
             size = 1.5, alpha = 0.7) +
  scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "RdYlBu"))) +
  labs(
    title = "Geographic Distribution of Listings Price in Los Angeles",
    x = "Longitude", y = "Latitude",
    color = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE}
# Room Type Distribution
ggplot(listings_data, aes(reorder(room_type, room_type, function(x) -length(x)), fill = room_type)) +
  geom_bar(color = "black") +
  scale_fill_manual(values = c("#D62828", "#F77F00", "#457B9D")) +
  labs(title = "Room Type Distribution", x = "Room Type", y = "Count") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  ) +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position = position_stack(vjust = 0.5),
    color = c("white", "white", "black"),
    size = 4.5
  )
```

```{r echo=FALSE}
# Price Distribution of Different Room Types
# boxplot
ggplot(listings_data, aes(x = room_type, y = price, fill = room_type)) +
  geom_boxplot() +
  # scale_fill_brewer(palette = "Set2") +
  scale_fill_manual(values = c("#D62828", "#F77F00", "#457B9D")) +
  theme_minimal() +
  labs(title = "Price Distribution of Different Room Types",
       x = "Room Type",
       y = "Price") +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Accommodates
p1 <- ggplot(listings_data, aes(x = accommodates, y = price)) +
  geom_point(color = "#003049", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FFBD00") +  # Add a linear model trendline
  labs(title = "Price vs Accommodates", x = "Accommodates", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Bathrooms
p2 <- ggplot(listings_data, aes(x = bathrooms, y = price)) +
  geom_point(color = "#D62828",alpha = 0.6) +
  geom_smooth(method = "lm", color = "#023E8A") +
  labs(title = "Price vs Bathrooms", x = "Bathrooms", y = "Price") +
  ylim(c(0, 700)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Bedrooms
p3 <- ggplot(listings_data, aes(x = bedrooms, y = price)) +
  geom_point(color = "#F77F00", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#C1121F") +
  labs(title = "Price vs Bedrooms", x = "Bedrooms", y = "Price") +
  xlim(c(0, 20)) +
  ylim(c(0, 700)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Beds
p4 <- ggplot(listings_data, aes(x = beds, y = price)) +
  geom_point(color = "#FCBF49", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#6A994E") +
  labs(title = "Price vs Beds", x = "Beds", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r fig.width=8,fig.height=6,echo=FALSE,message=FALSE,warning=FALSE}
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

看一下评分数量的分布，来决定评分是否可以作为预测价格的指标

```{r echo=FALSE,warning=FALSE}
# Distribution for Number of Reviews
ggplot(listings_data, aes(x = number_of_reviews)) +
  geom_histogram(binwidth = 20, fill = "#DA2C38", color = "black") +
  geom_density(aes(y = after_stat(count) * 10), color = "#226F54", linewidth = 1) +
  xlim(c(0,500)) +
  ylim(c(0,4000)) +
  labs(title = "Distribution for Number of Reviews", x = "Number of Reviews", y = "Count") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

画一张评分和价格的关系图

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Overall Rating
p5 <- ggplot(listings_data, aes(x = review_scores_rating, y = price)) +
  geom_point(color = "#003049", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FFBD00") +  # Add a linear model trendline
  labs(title = "Price vs Overall Rating", x = "Overall Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Accuray Rating
p6 <- ggplot(listings_data, aes(x = review_scores_accuracy, y = price)) +
  geom_point(color = "#D62828",alpha = 0.6) +
  geom_smooth(method = "lm", color = "#023E8A") +
  labs(title = "Price vs Accuray Rating", x = "Accuray Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Cleanliness Rating
p7 <- ggplot(listings_data, aes(x = review_scores_cleanliness, y = price)) +
  geom_point(color = "#F77F00", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#C1121F") +
  labs(title = "Price vs Cleanliness Rating", x = "Cleanliness Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Checkin Rating
p8 <- ggplot(listings_data, aes(x = review_scores_checkin, y = price)) +
  geom_point(color = "#FCBF49", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#6A994E") +
  labs(title = "Price vs Checkin Rating", x = "Checkin Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Communication Rating
p9 <- ggplot(listings_data, aes(x = review_scores_communication, y = price)) +
  geom_point(color = "#226F54", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#DA2C38") +
  labs(title = "Price vs Communication Rating", x = "Communication Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Location Rating
p10 <- ggplot(listings_data, aes(x = review_scores_location, y = price)) +
  geom_point(color = "#5E548E", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#9E2A2B") +
  labs(title = "Price vs Location Rating", x = "Location Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Value Rating
p11 <- ggplot(listings_data, aes(x = review_scores_value, y = price)) +
  geom_point(color = "#FFD60A", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#003566") +
  labs(title = "Price vs Value Rating", x = "Value Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r fig.width=8,fig.height=12,echo=FALSE,message=FALSE,warning=FALSE}
grid.arrange(p5, p6, p7, p8, p9, p10, p11, ncol = 2)
```

### Fitting Model

#### Split Dataset into train_data and test_data

为了确保类别平衡，您可以使用 **`createDataPartition`** 函数来自 **`caret`** 包，这个函数能够进行分层抽样，保证训练集和测试集中类别的代表性。

```{r echo=FALSE,warning=FALSE}
set.seed(123)
# Stratified sampling using createDataPartition
splitIndex <- createDataPartition(listings_data$host_neighbourhood, p = 0.8, list = FALSE)

# Split data set
train_data <- listings_data[splitIndex, ]
test_data <- listings_data[-splitIndex, ]
```

#### Model1: Null Model

```{r echo=FALSE}
fit_null <- lm(price ~ 1, data = train_data)
summary(fit_null)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_null), resid(fit_null), col = "#003566", xlim = c(150,250),
     main = "Residual Plot of Null Model", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_null), col = "#003566", main = "Q-Q Plot of Null Model")
qqline(resid(fit_null), col = "#D62828")  # Add a guide line
```

Null Model的结果显示，price的平均值大约是207.31。这个模型没有使用任何预测变量，只是简单地预测所有Airbnb房源的平均价格。

#### Model2: Complete Pooling Model (Linear Regression)

在上面的eda中，我们意识到价格分布呈现出明显的右偏（或正偏）特征，即大多数房源的价格较低，但也有少数房源价格非常高。考虑到这种偏态分布，线性模型（LM）可能不是最佳选择，因为LM假设响应变量近似正态分布。所以我们使用对数变换来处理响应变量，使其更接近正态分布，从而拟合线性模型。

如何选择交叉项

```{r echo=FALSE}
fit_lin <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location, 
              data = train_data)
summary(fit_lin)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_lin), resid(fit_lin), col = "#003566",
     main = "Residual Plot of Linear Regression Model", 
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_lin), col = "#003566", main = "Q-Q Plot of Linear Regression Model")
qqline(resid(fit_lin), col = "#D62828")  # Add a guide line
```

```{r echo=FALSE}
# Get summary
coef_fit_lin <- summary(fit_lin)

# Extract coefficients and confidence intervals
coef_df <- data.frame(
  Estimate = coef_fit_lin$coefficients[, "Estimate"],
  Std_Error = coef_fit_lin$coefficients[, "Std. Error"],
  term = row.names(coef_fit_lin$coefficients)
)

# Confidence intervals
coef_df$CI_low <- coef_df$Estimate - 1.96 * coef_df$Std_Error
coef_df$CI_high <- coef_df$Estimate + 1.96 * coef_df$Std_Error

# Coefficient estimates
ggplot(coef_df, aes(x = term, y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
  labs(
    title = 'Coefficient Estimates of Linear Regression Model',
    x = '', y = 'Estimate'
    )
```

模型的**`Multiple R-squared`**值为0.4524，表明模型解释了大约45.24%的**`price`**变量的变异性。虽然这个值表明模型有一定的解释力，但仍有超过一半的变异性未被模型解释。

#### Model3: Linear Regression Model with Interaction Term

```{r echo=FALSE}
fit_lin2 <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location +
                latitude:longitude + accommodates:bedrooms +
                review_scores_rating:review_scores_location, 
              data = train_data)
summary(fit_lin2)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_lin2), resid(fit_lin2), col = "#003566",
     main = "Residual Plot of Linear Regression Model with Interaction Term",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_lin2), col = "#003566", 
       main = "Q-Q Plot of Linear Regression Model with Interaction Term")
qqline(resid(fit_lin2), col = "#D62828")  # Add a guide line
```

```{r echo=FALSE}
# Get summary
coef_fit_lin2 <- summary(fit_lin2)

# Extract coefficients and confidence intervals
coef_df2 <- data.frame(
  Estimate = coef_fit_lin2$coefficients[, "Estimate"],
  Std_Error = coef_fit_lin2$coefficients[, "Std. Error"],
  term = row.names(coef_fit_lin2$coefficients)
)

# Confidence intervals
coef_df2$CI_low <- coef_df2$Estimate - 1.96 * coef_df2$Std_Error
coef_df2$CI_high <- coef_df2$Estimate + 1.96 * coef_df2$Std_Error

# Coefficient estimates
ggplot(coef_df2, aes(x = term, y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
  labs(
    title = 'Coefficient Estimates of Linear Regression Model with Interaction Term',
    x = '', y = 'Estimate'
    )
```

#### Model4: No Pooling Model

no pooling就是加一个factor

```{r echo=FALSE}
fit_no_pooling <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location +
                latitude:longitude + accommodates:bedrooms +
                review_scores_rating:review_scores_location + factor(host_neighbourhood),
                data = train_data)
summary(fit_no_pooling)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_no_pooling), resid(fit_no_pooling), col = "#003566",
     main = "Residual Plot of No Pooling Model",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_no_pooling), col = "#003566", main = "Q-Q Plot of No Pooling Model")
qqline(resid(fit_no_pooling), col = "#D62828")  # Add a guide line
```

#### Model5: Partial Pooling Model

如何选择分类变量

fit_partial_pooling

```{r echo=FALSE,warning=FALSE}
fit_partial_pooling <- lmer(log(price) ~ host_is_superhost + latitude + longitude + 
                              room_type + accommodates + bathrooms + bedrooms + beds +
                              minimum_nights + number_of_reviews + review_scores_rating +
                              review_scores_location + latitude:longitude + 
                              accommodates:bedrooms +
                              review_scores_rating:review_scores_location + 
                              (1 | host_neighbourhood), 
                            data = train_data)
summary(fit_partial_pooling)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_partial_pooling), resid(fit_partial_pooling), col = "#003566",
     main = "Residual Plot of Partial Pooling Model",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_partial_pooling), col = "#003566", main = "Q-Q Plot of Partial Pooling Model")
qqline(resid(fit_partial_pooling), col = "#D62828")  # Add a guide line
```

## Results Analysis and Discussion

颜色越红，rmse越小

#### Null Model

```{r echo=FALSE}
# Null Model
# Predict the response variable of the test set
test_predictions1 <- predict(fit_null, newdata = test_data)
# RMSE
rmse1 <- sqrt(mean((test_data$price - test_predictions1)^2))
```

```{r echo=FALSE}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - test_predictions1)^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = test_predictions1, color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Null Model",
    x = "True Value", y = "Predictions") +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  ylim(0, 600) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

#### Complete Pooling Model (Linear Regression)

```{r echo=FALSE}
# Complete Pooling
# Predict the response variable of the test set
test_predictions2 <- predict(fit_lin, newdata = test_data)
# RMSE
rmse2 <- sqrt(mean((test_data$price - exp(test_predictions2))^2))
```

```{r echo=FALSE,warning=FALSE}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions2))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions2), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Complete Pooling Model (Linear Regression)",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

#### Linear Regression Model with Interaction Term

```{r echo=FALSE}
# Linear Regression Model with Interaction Term
# Predict the response variable of the test set
test_predictions3 <- predict(fit_lin2, newdata = test_data)
# RMSE
rmse3 <- sqrt(mean((test_data$price - exp(test_predictions3))^2))
```

```{r}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions3))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions3), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Linear Regression Model with Interaction Term",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

#### No Pooling Model

```{r echo=FALSE}
# No Pooling Model
# Predict the response variable of the test set
test_predictions4 <- predict(fit_no_pooling, newdata = test_data)
# RMSE
rmse4 <- sqrt(mean((test_data$price - exp(test_predictions4))^2))
```

```{r echo=FALSE,warning=FALSE}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions4))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions4), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - No Pooling Model",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

#### Partial Pooling Model

```{r echo=FALSE}
# Partial Pooling Model
# Predict the response variable of the test set
test_predictions5 <- predict(fit_partial_pooling, newdata = test_data)
# RMSE
rmse5 <- sqrt(mean((test_data$price - exp(test_predictions5))^2))
```

```{r echo=FALSE}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions5))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions5), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Partial Pooling Model",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

```{r echo=FALSE}
# Create dataframe
model_comparison <- data.frame(
  Model = c("Null Model", 
            "Complete Pooling Model (Linear Regression)", 
            "Linear Regression Model with Interaction Term", 
            "No Pooling Model", 
            "Partial Pooling Model"),
  RMSE = c(107.05792, 84.35703, 80.32188, 77.19066, 77.04541)
)

# Use kable to generate tables
kable(model_comparison, caption = "Comparison of Different Models", align = 'c')
```

## Reference

[1] *Deboosere, R., Kerrigan, D. J., Wachsmuth, D., & El-Geneidy, A. (2019). Location, location and professionalization: a multilevel hedonic analysis of Airbnb listing prices and revenue. Regional Studies, Regional Science, 6(1), 143-156.*

[2] *Jiao, J., & Bai, S. (2020). An empirical analysis of Airbnb listings in forty American cities. Cities, 99, 102618.*

[3] *Guttentag, D. (2019). Progress on Airbnb: A literature review. Journal of Hospitality and Tourism Technology, 10(4)*

## Appendix
