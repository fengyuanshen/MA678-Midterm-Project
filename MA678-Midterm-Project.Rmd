---
title: "Data-Driven Analysis and Forecasting of the Los Angeles Airbnb Market"
subtitle : "MA678 Midterm Project"
author: "Fengyuan Shen (Vincent)"
date: "2023-12-09"
output: 
  pdf_document:
   latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="pdf",fig.align  = 'center')
```

# Abstract

This report conducts a data-driven analysis to forecast and understand the determinants of Airbnb listing prices in Los Angeles. With the rise of Airbnb as a significant player in the short-term rental market, this study provides a detailed examination of the factors influencing pricing strategies. It employs a robust statistical approach, starting from meticulous data cleaning to exploratory data analysis, and progresses to the development and comparison of multiple predictive models. The models range from simple linear regressions to more sophisticated partial pooling models, each analyzed for its predictive accuracy using the Root Mean Square Error (RMSE) metric. The findings are synthesized to reveal insights about the Los Angeles Airbnb market, contributing to the body of knowledge with practical analytical methodologies for pricing predictions in the sharing economy. The report's structured approach---from literature review to model evaluation---offers a clear narrative, making it a valuable resource for academics and practitioners interested in the economics of peer-to-peer accommodation platforms.

# Introduction

Airbnb has revolutionized the landscape of short-term accommodation, presenting a flexible alternative to traditional hotel stays. Its emergence as a major player in the hospitality industry has prompted extensive research into its economic impact, regulatory challenges, and influence on local real estate markets.

This project aims to dissect and predict the pricing mechanisms of Airbnb listings in Los Angeles, a city with a vibrant and diverse short-term rental market. By leveraging statistical models, I endeavor to understand the factors that drive listing prices and to forecast them accurately. The methodology employed encompasses data cleaning, exploratory data analysis, and the construction of various predictive models, ranging from simple averages to complex hierarchical models.

The report is structured to walk the reader through the research process systematically. It begins with a literature review that sets the stage for understanding the current academic and practical perspectives on Airbnb. This is followed by a detailed description of the data preprocessing steps, ensuring the robustness of subsequent analyses. The main body of the report delves into exploratory data analysis, model building and validation, where each model's assumptions, strengths, and limitations are carefully examined. Finally, the report culminates in a discussion that synthesizes the findings, offering insights to the Airbnb market in Los Angeles.

# Literature Review

In recent years, the rise and development of Airbnb has had a profound impact on urban housing markets and community dynamics. Studies have shown that the distribution of Airbnb listings is influenced by a number of factors. Deboosere et al.[1] uses hedonic regression models to analyze Airbnb transactions in New York City. This study finds that locational factors, particularly transit accessibility, greatly influence listing prices and revenues. It also indicates a trend towards the professionalization of the short-term rental market, leading to increased revenue for a smaller segment of hosts and potentially displacing long-term residents in accessible neighborhoods.

According to a comprehensive review by Guttentag [2][3] of 132 peer-reviewed journal articles, research on Airbnb has been categorized into six primary domains: the preferences and motivations of Airbnb guests, the incentives and objectives of hosts, the impact of Airbnb on local destinations, regulatory aspects, its influence on the tourism sector, and the operational dynamics of the company itself. The study highlights that Airbnb rentals tend to be located in areas with better transit services, proximity to city centers, and higher median house values and incomes, suggesting a risk of social inequality in the sharing economy.

In summary, these studies highlight a variety of factors that can affect Airbnb's listing prices. These insights have informed the modeling and analysis in my project, which focuses on identifying and analyzing the factors that can impact the pricing of Airbnb listings. This involves examining how elements like location, socioeconomic status, and broader market trends.

# Method

The initial dataset was segmented into ten distinct sections. To facilitate a comprehensive analysis, I consolidated these segments into a single dataset, subsequently named **`listings.csv`**.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(leaflet)
library(ggmap)
library(reshape2)
library(gridExtra)
library(lubridate)
library(stringr)
library(lme4)
library(rstanarm)
library(caTools)
library(caret)
library(knitr)
```

```{r echo=FALSE}
# listings <- read.csv("data/listings.csv", header = T)
# calendar <- read.csv("data/calendar.csv", header = T)
# reviews <- read.csv("data/reviews.csv", header = T)
```

```{r echo=FALSE}
# Combine data
# file_list <- list.files(path = "listings_data", pattern = "*.csv", full.names = TRUE)
# combined_data <- bind_rows(lapply(file_list, read.csv))
# write.csv(combined_data, "listings_data/listings.csv", row.names = FALSE)
```

```{r echo=FALSE}
# read csv
listings <- read.csv("data/listings.csv", header = T)
```

## Data Cleaning

In the data cleaning phase, the dataset comprised 75 variables, presenting a complexity that necessitated reduction for effective model fitting. Drawing upon insights gathered from the literature review, I meticulously chose over 30 variables deemed pertinent for predicting Airbnb's listing prices. The following table delineates a subset of these selected variables.

```{r echo=FALSE}
listings_data <- listings |> 
  select(id, host_id, host_name, host_since, host_response_time, host_response_rate,
         host_acceptance_rate, host_is_superhost, host_listings_count,
         host_identity_verified, latitude, longitude, property_type, room_type,
         accommodates, bathrooms_text, bedrooms, beds, price, minimum_nights,
         maximum_nights, number_of_reviews, review_scores_rating, review_scores_accuracy,
         review_scores_cleanliness, review_scores_checkin, review_scores_communication,
         review_scores_location, review_scores_value, instant_bookable, host_neighbourhood)
```

```{r echo=FALSE}
kable(head(listings_data[,c(3,4,16:19,23)]))
```

This is a summary of the dataset.

```{r echo=FALSE}
summary(listings_data)
```

Upon preliminary examination of the dataset, it becomes evident that the removal of missing values and outliers is imperative. Their presence could potentially skew the predictive accuracy of the model.

For the **`price`** column, I removed all non-numeric characters and calculated the first quartile (Q1) and third quartile (Q3) of the column, as well as the interquartile (IQR). They are then used to define a range of outliers. Finally, the dataset is filtered to retain only the price values in this range.

In the **`host_response_time`**, **`host_is_superhost`**, **`host_identity_verified`**, **`instant_bookable`**, **`bathrooms_text`**, and **`room_type`** columns, I converted categorical variables into numeric types, simultaneously filtering out rows containing NA values. This transformation not only streamlined the dataset but also enhanced its suitability for quantitative analysis and modeling.

Regarding the **`host_response_rate`** column, I transformed percentage strings into numeric values, thereby standardizing the data format for more effective subsequent analyses.

```{r echo=FALSE}
# Price
# Omit missing values
listings_data <- na.omit(listings_data)

# Converts the data format of the Price column
listings_data$price <- as.numeric(str_replace_all(listings_data$price, "[^0-9.]", ""))

# Remove outliers in the Price column
Q1 <- quantile(listings_data$price, 0.25)
Q3 <- quantile(listings_data$price, 0.75)
IQR <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
listings_data <- listings_data |> filter(price >= lower_bound & price <= upper_bound)
```

```{r echo=FALSE}
# Host response
# Converts categorical variables to numeric types
listings_data <- listings_data |> 
  mutate(host_response_time = case_when(
    host_response_time == "within an hour" ~ 0,
    host_response_time == "within a few hours" ~ 1,
    host_response_time  == "a few days or more" ~ 2,
    TRUE ~ NA  # If neither match, set the column to NA
  )) |> 
  filter(!is.na(host_response_time)) # Filter out rows with NA values
```

```{r echo=FALSE}
# Host is superhost
listings_data <- listings_data |> filter(host_is_superhost %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$host_is_superhost <- ifelse(listings_data$host_is_superhost == 'f', 0, 1)
```

```{r echo=FALSE}
# Host identify verified
listings_data <- listings_data |> filter(host_identity_verified %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$host_identity_verified <- ifelse(listings_data$host_identity_verified == 'f',
                                               0, 1)
```

```{r echo=FALSE}
# Instant bookable
listings_data <- listings_data |> filter(instant_bookable %in% c('f','t'))
# Converts categorical variables to numeric types
listings_data$instant_bookable <- ifelse(listings_data$instant_bookable == 'f', 0, 1)
```

```{r echo=FALSE, warning=FALSE}
# Converts a percentage string to a numeric type
listings_data$host_response_rate <- 
  as.numeric(sub("%", "", listings_data$host_response_rate)) / 100
listings_data$host_acceptance_rate <- 
  as.numeric(sub("%", "", listings_data$host_acceptance_rate)) / 100
listings_data <- drop_na(listings_data, host_response_rate, host_acceptance_rate)
```

```{r echo=FALSE}
# Bathrooms text
listings_data <- listings_data |> 
  mutate(bathrooms = case_when(
    bathrooms_text %in% c("Half-bath", "Shared half-bath") ~ 0.5,
    bathrooms_text %in% c("1 bath", "1 shared bath", "1 private bath") ~ 1,
    bathrooms_text %in% c("1.5 baths", "1.5 shared baths") ~ 1.5,
    bathrooms_text %in% c("2 baths", "2 shared baths") ~ 2,
    bathrooms_text %in% c("2.5 baths") ~ 2.5,
    bathrooms_text %in% c("3 baths", "3 shared baths") ~ 3,
    bathrooms_text %in% c("3.5 baths", "3.5 shared baths") ~ 3.5,
    bathrooms_text %in% c("4 baths") ~ 4,
    bathrooms_text %in% c("4.5 baths") ~ 4.5,
    bathrooms_text %in% c("5 baths") ~ 5,
    bathrooms_text %in% c("5.5 baths") ~ 5.5,
    bathrooms_text %in% c("6 baths") ~ 6,
    bathrooms_text %in% c("7 baths") ~ 7,
    bathrooms_text %in% c("7.5 baths") ~ 7.5,
    bathrooms_text %in% c("8 baths") ~ 8,
    bathrooms_text %in% c("11 baths", "11 shared baths", "11.5 shared baths") ~ 11,
    bathrooms_text %in% c("11.5 shared baths") ~ 11.5,
    TRUE ~ NA_real_  # For other values, set to NA
  )) |> 
  filter(!is.na(bathrooms)) |>   # Remove rows with NA in bathrooms
  # Keep bathrooms column after bathrooms_text
  relocate(bathrooms, .after = bathrooms_text) |>   
  select(-bathrooms_text)  # Remove the old bathrooms_text column
```

```{r echo=FALSE}
# Room type
listings_data <- listings_data |> 
  mutate(room = case_when(
    room_type %in% c("Entire home/apt") ~ 0,
    room_type %in% c("Private room") ~ 1,
    room_type %in% c("Hotel room") ~ 2,
    TRUE ~ NA_real_  # For other values, set to NA
  )) |> 
  filter(!is.na(room)) |>  # Remove rows with NA in room_type
  # Keep room column after bathrooms_text
  relocate(room, .after = room_type)
```

## EDA

Following the completion of the data cleaning process, the subsequent phase involves conducting exploratory data analysis (EDA). This critical step will facilitate a deeper and more nuanced understanding of the dataset.

Initially, to ascertain the linear relationships between various variables, I constructed a heatmap. This graphical representation elucidates the correlation coefficients among different variables, providing a visual overview of their interrelationships.

```{r fig.width=7,fig.height=6,echo=FALSE}
# Heatmap
# Select numerical columns for correlation analysis
numeric_data <- listings_data[, c('host_response_time', 'host_response_rate',
                                  'host_acceptance_rate', 'host_is_superhost',
                                  'host_listings_count', 'host_identity_verified',
                                  'latitude', 'longitude', 'room', 'accommodates',
                                  'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights',
                                  'maximum_nights', 'number_of_reviews', 
                                  'review_scores_rating', 'review_scores_accuracy',
                                  'review_scores_cleanliness', 'review_scores_checkin',
                                  'review_scores_communication', 'review_scores_location',
                                  'review_scores_value', 'instant_bookable')]

# Correlation matrix
correlation_matrix <- cor(numeric_data, use="complete.obs")

# Heatmap
melted_correlation <- melt(correlation_matrix)
ggplot(data = melted_correlation, aes(Var1, Var2, fill = value)) +
    geom_tile() +
    geom_text(aes(label = sprintf("%.2f", value)), size = 1.7, vjust = 0.5) +
    scale_fill_gradientn(colours = c("#03045E", "#023E8A", "#277DA1", "#577590", "#4D908E",
                                     "#43AA8B", "#90BE6D", "#F9C74F", "#F9844A", "#F8961E",
                                     "#F3722C", "#F94144", "#DC2F02", "#D00000"),
                         limits = c(-1, 1)) +
    theme_minimal() +
    labs(title = "Correlation Matrix of Variables", x = '', y = '') +
    theme(
      plot.title = element_text(hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
      )
```

The heatmap analysis reveals that the **`price`** variable exhibits significant correlations with several factors, including **`host_is_superhost`**, **`room_type`**, **`accommodates`**, **`bathrooms`**, **`bedrooms`**, **`beds`**, **`minimum_nights`**, **`number_of_reviews`**, **`review_scores_ratings`**, and **`review_scores_location`**.

However, it is crucial to note that the correlation matrix primarily reflects linear relationships between variables. In some instances, the associations might be non-linear, as exemplified by the relationship between **`price`** and geographical coordinates (**`latitude`** and **`longitude`**). Consistent with insights from existing literature, Airbnb's listing price is influenced by geographic location. Accordingly, incorporating **`latitude`** and **`longitude`** into the model building process is a critical step to capture these complex spatial dynamics.

Before delving into the exploration of other variables, an initial analysis was conducted to examine the distribution of Airbnb's listing price.

```{r echo=FALSE}
# Price Distribution
ggplot(listings_data, aes(x = price)) +
  geom_histogram(binwidth = 10, fill = "#D62828", color = "black") +
  geom_density(aes(y = after_stat(count) * 10), color = "#003566", linewidth = 1) +
  labs(title = "Price Distribution", x = "Price", y = "Frequency") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

The histogram indicates a right-skewed distribution, with a high frequency of listings priced at the lower end of the spectrum, suggesting that budget-friendly options are more common in the market. Most listings in Los Angeles are priced under \$200, although there are also listings priced over \$400. Notably, there is a long tail extending towards the higher price range, highlighting the presence of premium-priced listings.

Given the right-skewed distribution here, it is prudent to consider a logarithmic transformation of the price. This transformation aims to normalize the distribution, thereby satisfying one of the key assumptions of linear regression models which is the normality of the error terms.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Scatter plot of the relationship between location and price
register_stadiamaps(key = "5a10d16e-591e-4614-be7c-c5294374aac7")
los_angeles_map <- get_stadiamap(bbox = c(left = -118.55, bottom = 33.95, right = -118.15, 
                                          top = 34.25), zoom = 12, maptype = "outdoors")
```

```{r echo=FALSE,warning=FALSE}
ggmap(los_angeles_map) +
  geom_point(data = listings_data, aes(x = longitude, y = latitude, color = price), 
             size = 1.5, alpha = 0.7) +
  scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "RdYlBu"))) +
  labs(
    title = "Geographic Distribution of Listings Price in Los Angeles",
    x = "Longitude", y = "Latitude",
    color = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

The geographic distribution map of Airbnb's listing prices in Los Angeles visualizes the variation in pricing across different locations, with a higher density of listings in central and coastal areas. A gradient in pricing is observed, with more expensive listings often clustered in specific neighborhoods, potentially reflecting the desirability or accessibility of these areas. Conversely, more affordable listings appear to be more dispersed throughout the city.

```{r echo=FALSE}
# Room Type Distribution
ggplot(listings_data, aes(reorder(room_type, room_type, function(x) -length(x)), fill = room_type)) +
  geom_bar(color = "black") +
  scale_fill_manual(values = c("#D62828", "#F77F00", "#457B9D")) +
  labs(title = "Room Type Distribution", x = "Room Type", y = "Count") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  ) +
  geom_text(
    aes(label = after_stat(count)),
    stat = "count",
    position = position_stack(vjust = 0.5),
    color = c("white", "white", "black"),
    size = 4.5
  )
```

The bar chart depicts the room type distribution of Airbnb listings in Los Angeles, highlighting a predominant preference for **`Entire home/apartments`** which far outnumbers the other room types. This distribution suggests a significant market demand for entire homes or apartments, with limited availability or demand for hotel-style accommodations on the platform.

```{r echo=FALSE}
# Price Distribution of Different Room Types
# boxplot
ggplot(listings_data, aes(x = room_type, y = price, fill = room_type)) +
  geom_boxplot() +
  # scale_fill_brewer(palette = "Set2") +
  scale_fill_manual(values = c("#D62828", "#F77F00", "#457B9D")) +
  theme_minimal() +
  labs(title = "Price Distribution of Different Room Types",
       x = "Room Type",
       y = "Price") +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

I used boxplot to provide a compelling visualization of the price variance among different room types offered on Airbnb in Los Angeles. The distinct median prices and interquartile ranges across **`Entire home/apartments`**, **`Private room`**, and **`Hotel room`** indicate that room type is a significant factor influencing listing prices.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Accommodates
p1 <- ggplot(listings_data, aes(x = accommodates, y = price)) +
  geom_point(color = "#003049", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FFBD00") +  # Add a linear model trendline
  labs(title = "Price vs Accommodates", x = "Accommodates", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Bathrooms
p2 <- ggplot(listings_data, aes(x = bathrooms, y = price)) +
  geom_point(color = "#D62828",alpha = 0.6) +
  geom_smooth(method = "lm", color = "#023E8A") +
  labs(title = "Price vs Bathrooms", x = "Bathrooms", y = "Price") +
  ylim(c(0, 700)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Bedrooms
p3 <- ggplot(listings_data, aes(x = bedrooms, y = price)) +
  geom_point(color = "#F77F00", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#C1121F") +
  labs(title = "Price vs Bedrooms", x = "Bedrooms", y = "Price") +
  xlim(c(0, 20)) +
  ylim(c(0, 700)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Beds
p4 <- ggplot(listings_data, aes(x = beds, y = price)) +
  geom_point(color = "#FCBF49", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#6A994E") +
  labs(title = "Price vs Beds", x = "Beds", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r fig.width=8,fig.height=6,echo=FALSE,message=FALSE,warning=FALSE}
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

The scatter plots above illustrate the relationship between Airbnb listing prices and property features such as the number of people the property can accommodate, and the number of bathrooms, bedrooms, and beds available.

A positive trend is observed across all variables, with listing prices increasing in tandem with the number of accommodations, bathrooms, bedrooms, and beds. This suggests that properties with greater capacity and amenities are priced higher, reflecting their increased value to renters.

The clear trends demonstrated in these plots justify the inclusion of these variables in the model, as they are likely to be significant predictors of price.

```{r echo=FALSE,warning=FALSE}
# Distribution for Number of Reviews
ggplot(listings_data, aes(x = number_of_reviews)) +
  geom_histogram(binwidth = 20, fill = "#DA2C38", color = "black") +
  geom_density(aes(y = after_stat(count) * 10), color = "#226F54", linewidth = 1) +
  xlim(c(0,500)) +
  ylim(c(0,4000)) +
  labs(title = "Distribution for Number of Reviews", x = "Number of Reviews", y = "Count") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

From the histogram which illustrates a right-skewed distribution for the number of reviews per Airbnb listing, the presence of listings with an exceptionally high number of reviews suggests that there are a few highly popular or long-established listings. Given the significance of customer reviews in influencing rental desirability and trustworthiness, the number of reviews will be included as a variable in the model to capture its potential impact on pricing.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# Price vs Overall Rating
p5 <- ggplot(listings_data, aes(x = review_scores_rating, y = price)) +
  geom_point(color = "#003049", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#FFBD00") +  # Add a linear model trendline
  labs(title = "Price vs Overall Rating", x = "Overall Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Accuray Rating
p6 <- ggplot(listings_data, aes(x = review_scores_accuracy, y = price)) +
  geom_point(color = "#D62828",alpha = 0.6) +
  geom_smooth(method = "lm", color = "#023E8A") +
  labs(title = "Price vs Accuray Rating", x = "Accuray Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Cleanliness Rating
p7 <- ggplot(listings_data, aes(x = review_scores_cleanliness, y = price)) +
  geom_point(color = "#F77F00", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#C1121F") +
  labs(title = "Price vs Cleanliness Rating", x = "Cleanliness Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Checkin Rating
p8 <- ggplot(listings_data, aes(x = review_scores_checkin, y = price)) +
  geom_point(color = "#FCBF49", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#6A994E") +
  labs(title = "Price vs Checkin Rating", x = "Checkin Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Communication Rating
p9 <- ggplot(listings_data, aes(x = review_scores_communication, y = price)) +
  geom_point(color = "#226F54", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#DA2C38") +
  labs(title = "Price vs Communication Rating", x = "Communication Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Location Rating
p10 <- ggplot(listings_data, aes(x = review_scores_location, y = price)) +
  geom_point(color = "#5E548E", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#9E2A2B") +
  labs(title = "Price vs Location Rating", x = "Location Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

# Price vs Value Rating
p11 <- ggplot(listings_data, aes(x = review_scores_value, y = price)) +
  geom_point(color = "#FFD60A", alpha = 0.6) +
  geom_smooth(method = "lm", color = "#003566") +
  labs(title = "Price vs Value Rating", x = "Value Rating", y = "Price") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

```{r fig.width=8,fig.height=12,echo=FALSE,message=FALSE,warning=FALSE}
grid.arrange(p5, p6, p7, p8, p9, p10, p11, ncol = 2)
```

The scatter plots above analyze the relationship between Airbnb listing prices in Los Angeles and various customer ratings. The upward trend in the price versus overall rating plot suggests a positive correlation. Meanwhile, the location rating also shows a pronounced positive correlation with price, highlighting the potential influence of location on pricing decisions. In contrast, the plots for accuracy, cleanliness, check-in, communication, and value ratings show a less distinct relationship with price, suggesting that these factors might not be as influential in the pricing model.

As a result, given the visual trend of the overall and location rating, it is prudent to consider incorporating overall ratings and location-related ratings into the predictive model.

## Fitting Model

Based on the insights garnered from the literature and EDA process, I decided to include the following variables as predictors in the model: **`host_is_superhost`**, **`room_type`**, **`accommodates`**, **`bathrooms`**, **`bedrooms`**, **`beds`**, **`minimum_nights`**, **`number_of_reviews`**, **`review_scores_ratings`**, **`review_scores_location`**, along with geographical coordinates **`latitude`** and **`longitude`**.

Moving forward, to facilitate the validation of the model's predictive efficacy post-construction, I have partitioned the data into train set and test set. The model will be built on the train set, thereafter its performance will be assessed on the test set.

### Split the Dataset into train_data and test_data

To ensure class balance within the dataset, I utilized the **`createDataPartition`** function from the **`caret`** package, which performs stratified sampling to maintain representative proportions of classes in both the train and test sets. I allocated 80% of the data for training purposes and reserved 20% for testing.

```{r echo=FALSE,warning=FALSE}
set.seed(123)
# Stratified sampling using createDataPartition
splitIndex <- createDataPartition(listings_data$host_neighbourhood, p = 0.8, list = FALSE)

# Split data set
train_data <- listings_data[splitIndex, ]
test_data <- listings_data[-splitIndex, ]
```

### Model1: Null Model

$$lm(Price = \alpha)$$

```{r echo=FALSE}
fit_null <- lm(price ~ 1, data = train_data)
summary(fit_null)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_null), resid(fit_null), col = "#003566", xlim = c(150,250),
     main = "Residual Plot of Null Model", xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_null), col = "#003566", main = "Q-Q Plot of Null Model")
qqline(resid(fit_null), col = "#D62828")  # Add a guide line
```

The Null Model serves as a baseline for my regression analysis, assuming no predictors other than the intercept. The summary output indicates that the intercept, representing the average listing price when no predictors are included, is estimated at 207.2075 with a standard deviation of 0.9585. This model is statistically significant, as evidenced by the p-value of less than 2e-16. However, the large residual standard error of 108.8 suggests considerable unexplained variability in listing prices.

For the residual plot, I observe a very narrow vertical distribution of residuals, showing that the model does not capture the variance in the data. Also, the Q-Q Plot of the Null Model indicates that the residuals are not normally distributed.

Based on the above analysis, I would say that the Null Model, without any predictors, is insufficient for explaining the variance in the Airbnb listing prices.

### Model2: Complete Pooling Model (Linear Regression)

During the EDA process, it became evident that the distribution of listing prices was substantially right-skewed, with the majority of listings being lower-priced, while a minority were notably higher-priced. Given this skewed distribution, a linear model (LM) may not be the best choice because LM assumes that the response variables are approximately normally distributed. So I used a logarithmic transformation to process the response variable to make it closer to a normal distribution and thus fit a linear model.

$$
lm(log(price) = \alpha \\
+ \beta_1 \cdot host\_is\_superhost \\
+ \beta_2 \cdot latitude \\
+ \beta_3 \cdot longitude \\
+ \beta_4 \cdot room\_type \\
+ \beta_5 \cdot accommodates \\
$$ $$
+ \beta_6 \cdot bathrooms \\
+ \beta_7 \cdot bedrooms \\
+ \beta_8 \cdot beds \\
+ \beta_9 \cdot minimum\_nights \\
+ \beta_{10} \cdot number\_of\_reviews \\
$$ $$
+ \beta_{11} \cdot review\_scores\_rating \\
+ \beta_{12} \cdot review\_scores\_location)
$$

```{r echo=FALSE}
fit_lin <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location, 
              data = train_data)
summary(fit_lin)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_lin), resid(fit_lin), col = "#003566",
     main = "Residual Plot of Linear Regression Model", 
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_lin), col = "#003566", main = "Q-Q Plot of Linear Regression Model")
qqline(resid(fit_lin), col = "#D62828")  # Add a guide line
```

The Complete Pooling model was estimated using a Linear Regression approach. The summary of the regression model indicates all the variables are statistically significant predictors of the logarithmically transformed price, as demonstrated by the p-values less than 0.05.

The coefficients from the model provide insights into the relative impact of each predictor. For instance, being a superhost and having additional bathrooms and bedrooms are associated with higher prices, while the type of room being either a hotel room or a private room typically corresponds with a lower price relative to entire homes/apartments.

The Adjusted R-squared value of the model is 0.4525, indicating that the model explains about 45.25% of the variability of the price variable.

The Residual Plot of the Linear Regression Model shows residuals scattered around the zero line, which is indicative of a good fit, but the pattern suggests potential heteroscedasticity as the variance of residuals appears to increase with the fitted values.

The Q-Q Plot of the Linear Regression Model reveals some deviation from normality, particularly in the tails of the distribution, suggesting that the normality assumption may not fully hold. This could be due to outliers.

### Model3: Linear Regression Model with Interaction Term

$$
lm(log(price) = \alpha \\
+ \beta_1 \cdot host\_is\_superhost \\
+ \beta_2 \cdot latitude \\
+ \beta_3 \cdot longitude \\
+ \beta_4 \cdot room\_type \\
+ \beta_5 \cdot accommodates \\
$$ $$
+ \beta_6 \cdot bathrooms \\
+ \beta_7 \cdot bedrooms \\
+ \beta_8 \cdot beds \\
+ \beta_9 \cdot minimum\_nights \\
+ \beta_{10} \cdot number\_of\_reviews \\
$$ $$
+ \beta_{11} \cdot review\_scores\_rating \\
+ \beta_{12} \cdot review\_scores\_location \\
+ \beta_{13} \cdot latitude*longitude \\
$$ $$
+ \beta_{14} \cdot accommodates*bedrooms \\
+ \beta_{15} \cdot review\_scores\_rating*review\_scores\_location)
$$

```{r echo=FALSE}
fit_lin2 <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location +
                latitude:longitude + accommodates:bedrooms +
                review_scores_rating:review_scores_location, 
              data = train_data)
summary(fit_lin2)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_lin2), resid(fit_lin2), col = "#003566",
     main = "Residual Plot of Linear Regression Model with Interaction Term",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_lin2), col = "#003566", 
       main = "Q-Q Plot of Linear Regression Model with Interaction Term")
qqline(resid(fit_lin2), col = "#D62828")  # Add a guide line
```

This model is an extension from the basic model to include interactions between certain variables. Specifically, interaction terms between latitude and longitude, accommodates and bedrooms, and review_scores_rating and review_scores_location have been included, suggesting that I believe the influence of location on price is not uniform across the geographic space, that the relationship between the number of people accommodated and the price varies with the number of bedrooms, and that the impact of review scores on price is moderated by their respective locations.

This model retains many of the predictors from the previous model, with all variables showing statistical significance in predicting the logarithmically transformed price.

The Residual Plot and Q-Q Plot show the similar pattern to the previous model. However, the adjusted R-squared value of 0.4766 represents a slight improvement over the previous model, explaining approximately 47.66% of the variability in the logarithmically transformed price. Therefore, the inclusion of interaction terms in the model did slghtly improve the model.

### Model4: No Pooling Model

$$
lm(log(price) = \alpha \\
+ \beta_1 \cdot host\_is\_superhost \\
+ \beta_2 \cdot latitude \\
+ \beta_3 \cdot longitude \\
+ \beta_4 \cdot room\_type \\
+ \beta_5 \cdot accommodates \\
$$ $$
+ \beta_6 \cdot bathrooms \\
+ \beta_7 \cdot bedrooms \\
+ \beta_8 \cdot beds \\
+ \beta_9 \cdot minimum\_nights \\
+ \beta_{10} \cdot number\_of\_reviews \\
$$ $$
+ \beta_{11} \cdot review\_scores\_rating \\
+ \beta_{12} \cdot review\_scores\_location \\
+ \beta_{13} \cdot latitude*longitude \\
$$ $$
+ \beta_{14} \cdot accommodates*bedrooms \\
+ \beta_{15} \cdot review\_scores\_rating*review\_scores\_location \\
$$ $$
+ factor(host\_neighbourhood))
$$

```{r echo=FALSE}
fit_no_pooling <- lm(log(price) ~ host_is_superhost + latitude + longitude + room_type + 
                accommodates + bathrooms + bedrooms + beds + minimum_nights +
                number_of_reviews + review_scores_rating + review_scores_location +
                latitude:longitude + accommodates:bedrooms +
                review_scores_rating:review_scores_location + factor(host_neighbourhood),
                data = train_data)

# Display summary of the coefficients with a limited number of coefficients
coef_summary <- summary(fit_no_pooling)$coefficients

# Print the first 23 coefficients
print(coef_summary[1:23, ])

# Print the specified summary statistics
cat("\nResidual standard error: ", summary(fit_no_pooling)$sigma, " on ", 
    fit_no_pooling$df.residual, " degrees of freedom\n")
cat("Multiple R-squared: ", summary(fit_no_pooling)$r.squared, "\tAdjusted R-squared: ",
    summary(fit_no_pooling)$adj.r.squared, "\n")
cat("F-statistic: ", summary(fit_no_pooling)$fstatistic[1], " on ", 
    summary(fit_no_pooling)$fstatistic[2], " and ", summary(fit_no_pooling)$fstatistic[3],
    " DF,  p-value: ", summary(fit_no_pooling)$fstatistic[4], "\n")
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_no_pooling), resid(fit_no_pooling), col = "#003566",
     main = "Residual Plot of No Pooling Model",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_no_pooling), col = "#003566", main = "Q-Q Plot of No Pooling Model")
qqline(resid(fit_no_pooling), col = "#D62828")  # Add a guide line
```

For the No Pooling Model, I included a neighborhood-specific effect, thereby capturing local variations that the Complete Pooling Model might miss. The model output suggests that all predictors are statistically significant, as indicated by their p-values.

The Residual Plot shows a random scatter of residuals around the zero line, indicating a well-fitted model with no apparent patterns that would suggest model misspecification, Which looks similar to the previous one.

The Q-Q Plot shows that the residuals are mostly aligned with the theoretical quantiles, but deviations are observed in the tails, which indicates that there may still be outliers or influential points affecting the model's assumptions.

The model's adjusted R-squared of approximately 0.5552 suggests that over 55.52% of the variability in the logarithmically transformed price is explained by the model, marking an improvement in fit compared to the Complete Pooling Model.

### Model5: Partial Pooling Model

$$
lm(log(price) = \alpha \\
+ \beta_1 \cdot host\_is\_superhost \\
+ \beta_2 \cdot latitude \\
+ \beta_3 \cdot longitude \\
+ \beta_4 \cdot room\_type \\
+ \beta_5 \cdot accommodates \\
$$ $$
+ \beta_6 \cdot bathrooms \\
+ \beta_7 \cdot bedrooms \\
+ \beta_8 \cdot beds \\
+ \beta_9 \cdot minimum\_nights \\
+ \beta_{10} \cdot number\_of\_reviews \\
$$ $$
+ \beta_{11} \cdot review\_scores\_rating \\
+ \beta_{12} \cdot review\_scores\_location \\
+ \beta_{13} \cdot latitude*longitude \\
$$ $$
+ \beta_{14} \cdot accommodates*bedrooms \\
+ \beta_{15} \cdot review\_scores\_rating*review\_scores\_location \\
$$ $$
+ (1 | host\_neighbourhood))
$$

```{r echo=FALSE,warning=FALSE}
fit_partial_pooling <- lmer(log(price) ~ host_is_superhost + latitude + longitude + 
                              room_type + accommodates + bathrooms + bedrooms + beds +
                              minimum_nights + number_of_reviews + review_scores_rating +
                              review_scores_location + latitude:longitude + 
                              accommodates:bedrooms +
                              review_scores_rating:review_scores_location + 
                              (1 | host_neighbourhood), 
                            data = train_data)
summary(fit_partial_pooling)
```

```{r echo=FALSE}
# Residual plot
plot(fitted(fit_partial_pooling), resid(fit_partial_pooling), col = "#003566",
     main = "Residual Plot of Partial Pooling Model",
     xlab = "Fitted Values", ylab = "Residuals")
abline(h = 0, col = "#D62828") # Add a horizontal line at y=0
```

```{r echo=FALSE}
# Q-Q Plot
qqnorm(resid(fit_partial_pooling), col = "#003566", main = "Q-Q Plot of Partial Pooling Model")
qqline(resid(fit_partial_pooling), col = "#D62828")  # Add a guide line
```

The Partial Pooling Model introduces random effects to account for variations within Airbnb's host neighborhoods, on top of the fixed effects considered in previous models. This approach allows me to capture inherent group-level variability in the price-setting behavior across different neighborhoods.

The Residual Plot and Q-Q Plot show the similar pattern to the previous one.

For the fixed effects, it can be seen that the predictors like **`host_is_superhost`**, **`latitude`**, **`longitude`**, **`room_type`**, and property characteristics such as **`accommodates`**, **`bathrooms`**, **`bedrooms`**, and **`beds`** remain significant.

The random effects for **`host_neighborhood`** suggest that there is a significant variance in price that can be attributed to the neighborhood level, justifying the inclusion of random effects in the model.

# Results Analysis

In the preceding analysis, I constructed five distinct models, each possessing unique strengths and weaknesses. To facilitate a more direct comparison of their predictive capabilities, I will deploy these models to forecast outcomes on the test set and compare the predictions against the actual values.

The Root Mean Square Error (RMSE) for each model has been computed to quantify their prediction accuracy. Additionally, I have created scatter plots to visually represent the predictive performance of each model. This comparative approach will enable an assessment of which model most effectively captures the nuances of the data, thereby guiding the selection of the optimal model for further application.

### Null Model

```{r echo=FALSE}
# Null Model
# Predict the response variable of the test set
test_predictions1 <- predict(fit_null, newdata = test_data)
# RMSE
rmse1 <- sqrt(mean((test_data$price - test_predictions1)^2))
```

```{r echo=FALSE,fig.align='center'}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - test_predictions1)^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = test_predictions1, color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Null Model",
    x = "True Value", y = "Predictions") +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  ylim(0, 600) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

### Complete Pooling Model (Linear Regression)

```{r echo=FALSE}
# Complete Pooling
# Predict the response variable of the test set
test_predictions2 <- predict(fit_lin, newdata = test_data)
# RMSE
rmse2 <- sqrt(mean((test_data$price - exp(test_predictions2))^2))
```

```{r echo=FALSE,warning=FALSE,fig.align='center'}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions2))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions2), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Complete Pooling",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

### Linear Regression Model with Interaction Term

```{r echo=FALSE}
# Linear Regression Model with Interaction Term
# Predict the response variable of the test set
test_predictions3 <- predict(fit_lin2, newdata = test_data)
# RMSE
rmse3 <- sqrt(mean((test_data$price - exp(test_predictions3))^2))
```

```{r echo=FALSE,fig.align='center'}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions3))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions3), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - LR with Interaction",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

### No Pooling Model

```{r echo=FALSE}
# No Pooling Model
# Predict the response variable of the test set
test_predictions4 <- predict(fit_no_pooling, newdata = test_data)
# RMSE
rmse4 <- sqrt(mean((test_data$price - exp(test_predictions4))^2))
```

```{r echo=FALSE,warning=FALSE,fig.align='center'}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions4))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions4), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - No Pooling",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

### Partial Pooling Model

```{r echo=FALSE}
# Partial Pooling Model
# Predict the response variable of the test set
test_predictions5 <- predict(fit_partial_pooling, newdata = test_data)
# RMSE
rmse5 <- sqrt(mean((test_data$price - exp(test_predictions5))^2))
```

```{r echo=FALSE,fig.align='center'}
# Calculate RMSE of each data point
RMSE_per_point <- sqrt((test_data$price - exp(test_predictions5))^2)

# Scatter plot
ggplot(test_data, aes(x = price, y = exp(test_predictions5), color = RMSE_per_point)) +
  geom_point() +
  scale_color_gradientn(colours = c("#D00000", "#DC2F02", "#F9844A", "#F9C74F", "#90BE6D",
                                    "#43AA8B", "#4D908E", "#577590", "#277DA1", "#014F86",
                                    "#023E8A", "#013A63", "#012A4A", "#03045E")) +
  labs(
    title = "True Values vs Predictions - Partial Pooling",
    x = "True Value", y = "Predictions"
    ) +
  geom_abline(intercept = 0, slope = 1, color = "black", linewidth = 0.8) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    )
```

```{r echo=FALSE}
# Create dataframe
model_comparison <- data.frame(
  Model = c("Null Model", 
            "Complete Pooling Model (Linear Regression)", 
            "Linear Regression Model with Interaction Term", 
            "No Pooling Model", 
            "Partial Pooling Model"),
  RMSE = c(107.05792, 84.35703, 80.32188, 77.19066, 77.04541)
)

# Use kable to generate tables
kable(model_comparison, caption = "Comparison of Different Models", align = 'c')
```

The scatter plots illustrate the predictive accuracy of the five models compared to the actual Airbnb listing prices, with the line of perfect prediction as a reference. The color intensity represents the RMSE for each prediction point, with darker colors indicating higher errors.

The Null Model shows a horizontal line of predictions, reflecting its simplistic assumption that all listings will have the average price. This model has the highest RMSE, suggesting it's the least accurate.

The Complete Pooling Model (Linear Regression) shows a greater spread of predictions, with many points aligning closer to the line of perfect prediction. However, there are still many points with high RMSE values, indicating substantial error for those predictions.

The Linear Regression Model with Interaction Term has a slightly improved spread of predictions, with more points close to the line of perfect prediction and fewer points with very high RMSE values, indicating that considering interaction effects has enhanced the model's predictive power.

The No Pooling Model shows a further improved alignment with the line of perfect prediction, suggesting that treating each listing individually, rather than assuming they are all the same, provides a better fit.

The Partial Pooling Model appears to be the most accurate, as indicated by the denser cluster of points around the line of perfect prediction and the lower RMSE values. This suggests that accounting for both fixed effects and random effects due to neighborhoods provides the best balance between capturing the common trend and accommodating the variability in prices across different neighborhoods. The RMSE comparison chart solidifies these observations, confirming that the Partial Pooling Model has the lowest RMSE.

In conclusion, the detailed analysis points to the Partial Pooling Model as the most effective for predicting Airbnb's listing prices in Los Angeles, offering the best balance between complexity and accuracy.

# Discussion and Limitation

While the Partial Pooling Model is superior in terms of predictive accuracy, the choice of model may also depend on the specific application and the interpretability requirements. If the goal is to understand specific neighborhood effects, the No Pooling or Partial Pooling models would be more appropriate. If interpretability and simplicity are more critical, the Complete Pooling or Interaction models might be preferred, despite the slight sacrifice in prediction accuracy.

These models also have some limitations, almost all the models are unduly influenced by outliers or points with high leverage that do not represent the general trend. Besides, some complex models, especially those with many predictors and interactions, are at risk of overfitting to the train data and may not generalize well to unseen data. What's more, as models become more complex, they often become harder to interpret. The Partial Pooling Model, for instance, can be difficult to explain to stakeholders without a statistical background.

# Reference

[1] Deboosere, R., Kerrigan, D. J., Wachsmuth, D., & El-Geneidy, A. (2019). *Location, location and professionalization: a multilevel hedonic analysis of Airbnb listing prices and revenue.*Regional Studies, Regional Science,6(1), 143-156.

[2] Jiao, J., & Bai, S. (2020). *An empirical analysis of Airbnb listings in forty American cities.*Cities,99, 102618.

[3] Guttentag, D. (2019). *Progress on Airbnb: A literature review.* Journal of Hospitality and Tourism Technology, 10(4)

[4] Gelman, A., Hill, J., & Vehtari, A. (2020). *Regression and other stories.* Cambridge University Press.

[5] Gelman, A., & Hill, J. (2006). *Data analysis using regression and multilevel/hierarchical models*. Cambridge university press.

```{r echo=FALSE}
# # Get summary
# coef_fit_lin <- summary(fit_lin)
# 
# # Extract coefficients and confidence intervals
# coef_df <- data.frame(
#   Estimate = coef_fit_lin$coefficients[, "Estimate"],
#   Std_Error = coef_fit_lin$coefficients[, "Std. Error"],
#   term = row.names(coef_fit_lin$coefficients)
# )
# 
# # Confidence intervals
# coef_df$CI_low <- coef_df$Estimate - 1.96 * coef_df$Std_Error
# coef_df$CI_high <- coef_df$Estimate + 1.96 * coef_df$Std_Error
# 
# # Coefficient estimates
# ggplot(coef_df, aes(x = term, y = Estimate)) +
#   geom_point() +
#   geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(hjust = 0.5),
#     axis.text.x = element_text(angle = 45, hjust = 1)
#     ) +
#   labs(
#     title = 'Coefficient Estimates of Linear Regression Model',
#     x = '', y = 'Estimate'
#     )
```

```{r echo=FALSE}
# # Get summary
# coef_fit_lin2 <- summary(fit_lin2)
# 
# # Extract coefficients and confidence intervals
# coef_df2 <- data.frame(
#   Estimate = coef_fit_lin2$coefficients[, "Estimate"],
#   Std_Error = coef_fit_lin2$coefficients[, "Std. Error"],
#   term = row.names(coef_fit_lin2$coefficients)
# )
# 
# # Confidence intervals
# coef_df2$CI_low <- coef_df2$Estimate - 1.96 * coef_df2$Std_Error
# coef_df2$CI_high <- coef_df2$Estimate + 1.96 * coef_df2$Std_Error
# 
# # Coefficient estimates
# ggplot(coef_df2, aes(x = term, y = Estimate)) +
#   geom_point() +
#   geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
#   theme_minimal() +
#   theme(
#     plot.title = element_text(hjust = 0.5),
#     axis.text.x = element_text(angle = 45, hjust = 1)
#     ) +
#   labs(
#     title = 'Coefficient Estimates of Linear Regression Model with Interaction Term',
#     x = '', y = 'Estimate'
#     )
```
